# quick_test.py - å¿«é€Ÿæµ‹è¯• Pinecone è¿æ¥å’ŒåŠŸèƒ½
from pinecone import Pinecone, ServerlessSpec
import json
import time

# åˆå§‹åŒ– Pinecone å®¢æˆ·ç«¯
pc = Pinecone(api_key="pcsk_4WvWXx_G5bRUFdFNzLzRHNM9rkvFMvC18TMRTaeYXVCxmWSPQLmKr4xAs4UaZg5NvVb69m")

# ç´¢å¼•é…ç½®
INDEX_NAME = "dementia-care-knowledge"
DIMENSION = 384  # all-MiniLM-L6-v2 æ¨¡å‹çš„ç»´åº¦

def test_pinecone_connection():
    """æµ‹è¯• Pinecone è¿æ¥"""
    print("ğŸ”„ Testing Pinecone connection...")

    try:
        # åˆ—å‡ºç°æœ‰ç´¢å¼•
        indexes = pc.list_indexes()
        print(f"âœ… Connected to Pinecone! Found {len(indexes)} indexes.")

        for idx in indexes:
            print(f"  - Index: {idx.name}")

        return True
    except Exception as e:
        print(f"âŒ Connection failed: {str(e)}")
        return False

def create_index_if_not_exists():
    """åˆ›å»ºç´¢å¼•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
    print(f"ğŸ”„ Checking if index '{INDEX_NAME}' exists...")

    try:
        existing_indexes = [idx.name for idx in pc.list_indexes()]

        if INDEX_NAME not in existing_indexes:
            print(f"ğŸ“ Creating new index: {INDEX_NAME}")

            pc.create_index(
                name=INDEX_NAME,
                dimension=DIMENSION,
                metric="cosine",
                spec=ServerlessSpec(
                    cloud="aws", 
                    region="us-east-1"
                )
            )

            print("â³ Waiting for index to be ready...")
            time.sleep(10)  # ç­‰å¾…ç´¢å¼•åˆå§‹åŒ–

            print("âœ… Index created successfully!")
        else:
            print("âœ… Index already exists!")

        return pc.Index(INDEX_NAME)

    except Exception as e:
        print(f"âŒ Failed to create index: {str(e)}")
        return None

def test_basic_operations(index):
    """æµ‹è¯•åŸºæœ¬çš„å‘é‡æ“ä½œ"""
    print("ğŸ§ª Testing basic vector operations...")

    try:
        # æµ‹è¯•å‘é‡æ•°æ®
        test_vectors = [
            {
                'id': 'test-001',
                'values': [0.1] * DIMENSION,  # ç®€å•çš„æµ‹è¯•å‘é‡
                'metadata': {
                    'title': 'æµ‹è¯•å‘é‡1',
                    'content': 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å‘é‡',
                    'type': 'test'
                }
            },
            {
                'id': 'test-002', 
                'values': [0.2] * DIMENSION,
                'metadata': {
                    'title': 'æµ‹è¯•å‘é‡2',
                    'content': 'è¿™æ˜¯å¦ä¸€ä¸ªæµ‹è¯•å‘é‡',
                    'type': 'test'
                }
            }
        ]

        # 1. ä¸Šä¼ å‘é‡
        print("ğŸ“¤ Uploading test vectors...")
        upsert_response = index.upsert(vectors=test_vectors)
        print(f"âœ… Uploaded {upsert_response.upserted_count} vectors")

        # ç­‰å¾…æ›´æ–°
        time.sleep(2)

        # 2. æŸ¥è¯¢å‘é‡
        print("ğŸ” Querying vectors...")
        query_response = index.query(
            vector=[0.15] * DIMENSION,  # æŸ¥è¯¢å‘é‡
            top_k=2,
            include_metadata=True
        )

        print(f"âœ… Found {len(query_response.matches)} similar vectors:")
        for match in query_response.matches:
            print(f"  - ID: {match.id}, Score: {match.score:.4f}")
            print(f"    Title: {match.metadata.get('title', 'N/A')}")

        # 3. è·å–ç´¢å¼•ç»Ÿè®¡
        print("ğŸ“Š Getting index statistics...")
        stats = index.describe_index_stats()
        print(f"âœ… Index contains {stats.total_vector_count} vectors")

        # 4. æ¸…ç†æµ‹è¯•æ•°æ®
        print("ğŸ§¹ Cleaning up test data...")
        index.delete(ids=['test-001', 'test-002'])
        print("âœ… Test data cleaned up")

        return True

    except Exception as e:
        print(f"âŒ Test operations failed: {str(e)}")
        return False

def upload_demo_knowledge(index):
    """ä¸Šä¼ æ¼”ç¤ºçŸ¥è¯†æ•°æ®"""
    print("ğŸ“š Uploading demo knowledge...")

    # éœ€è¦å…ˆå®‰è£… sentence-transformers
    try:
        from sentence_transformers import SentenceTransformer
        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        print("âœ… Embedding model loaded")
    except ImportError:
        print("âŒ sentence-transformers not installed. Run: pip install sentence-transformers")
        return False
    except Exception as e:
        print(f"âŒ Failed to load model: {str(e)}")
        return False

    # æ¼”ç¤ºçŸ¥è¯†æ•°æ®
    demo_chunks = [
        {
            "chunk_id": "demo-001",
            "title": "å¤±æ™ºç—‡åå¤§è­¦è¨Š",
            "content": "å¤±æ™ºç—‡çš„åå¤§è­¦è¨ŠåŒ…æ‹¬è¨˜æ†¶åŠ›æ¸›é€€ã€è¨ˆåŠƒäº‹æƒ…æˆ–è§£æ±ºå•é¡Œæœ‰å›°é›£ã€ç„¡æ³•å‹ä»»åŸæœ¬ç†Ÿæ‚‰çš„äº‹å‹™ç­‰ã€‚åŠæ—©ç™¼ç¾é€™äº›è­¦è¨Šæœ‰åŠ©æ–¼æ—©æœŸè¨ºæ–·å’Œæ²»ç™‚ã€‚",
            "chunk_type": "warning_sign",
            "keywords": ["å¤±æ™ºç—‡", "è­¦è¨Š", "è¨˜æ†¶åŠ›", "è¨ºæ–·"]
        },
        {
            "chunk_id": "demo-002", 
            "title": "BPSDè¡Œç‚ºå¿ƒç†ç—‡ç‹€",
            "content": "BPSDæŒ‡å¤±æ™ºç—‡æ‚£è€…çš„è¡Œç‚ºå¿ƒç†ç—‡ç‹€ï¼ŒåŒ…æ‹¬éŠèµ°ã€æ”»æ“Šè¡Œç‚ºã€å¦„æƒ³ã€å¹»è¦ºç­‰ã€‚äº†è§£é€™äº›ç—‡ç‹€æœ‰åŠ©æ–¼æä¾›é©ç•¶çš„ç…§è­·ã€‚",
            "chunk_type": "bpsd_symptom",
            "keywords": ["BPSD", "è¡Œç‚ºç—‡ç‹€", "éŠèµ°", "ç…§è­·"]
        },
        {
            "chunk_id": "demo-003",
            "title": "å¤±æ™ºç—‡æºé€šæŠ€å·§", 
            "content": "èˆ‡å¤±æ™ºç—‡æ‚£è€…æºé€šæ™‚è¦ä¿æŒè€å¿ƒï¼Œä½¿ç”¨ç°¡å–®æ˜ç¢ºçš„èªè¨€ï¼Œé¿å…çˆ­è¾¯æˆ–ç³¾æ­£ï¼Œå¤šç”¨è‚¢é«”èªè¨€å’Œè¡¨æƒ…ä¾†è¡¨é”é—œæ„›ã€‚",
            "chunk_type": "coping_strategy",
            "keywords": ["æºé€š", "æŠ€å·§", "è€å¿ƒ", "è‚¢é«”èªè¨€"]
        }
    ]

    try:
        vectors_to_upload = []

        for chunk in demo_chunks:
            # ç”ŸæˆåµŒå…¥å‘é‡
            content = f"{chunk['title']} {chunk['content']} {' '.join(chunk['keywords'])}"
            embedding = model.encode(content).tolist()

            # å‡†å¤‡å‘é‡æ•°æ®
            vector_data = {
                'id': chunk['chunk_id'],
                'values': embedding,
                'metadata': {
                    'title': chunk['title'],
                    'content': chunk['content'][:500],  # é™åˆ¶é•¿åº¦
                    'chunk_type': chunk['chunk_type'],
                    'keywords': json.dumps(chunk['keywords'])
                }
            }

            vectors_to_upload.append(vector_data)
            print(f"âœ… Prepared: {chunk['chunk_id']}")

        # æ‰¹é‡ä¸Šä¼ 
        upsert_response = index.upsert(vectors=vectors_to_upload)
        print(f"ğŸ‰ Successfully uploaded {upsert_response.upserted_count} demo vectors!")

        # ç­‰å¾…ç´¢å¼•æ›´æ–°
        time.sleep(3)

        # æµ‹è¯•æŸ¥è¯¢
        print("ğŸ” Testing demo query...")
        test_query = "å¤±æ™ºç—‡çš„ç—‡çŠ¶æœ‰å“ªäº›ï¼Ÿ"
        query_embedding = model.encode(test_query).tolist()

        results = index.query(
            vector=query_embedding,
            top_k=3,
            include_metadata=True
        )

        print(f"âœ… Query results for '{test_query}':")
        for i, match in enumerate(results.matches, 1):
            print(f"  {i}. {match.metadata['title']} (Score: {match.score:.4f})")
            print(f"     {match.metadata['content'][:100]}...")

        return True

    except Exception as e:
        print(f"âŒ Failed to upload demo knowledge: {str(e)}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ Starting Pinecone Quick Test")
    print("=" * 50)

    # 1. æµ‹è¯•è¿æ¥
    if not test_pinecone_connection():
        return

    # 2. åˆ›å»ºç´¢å¼•
    index = create_index_if_not_exists()
    if not index:
        return

    # 3. æµ‹è¯•åŸºæœ¬æ“ä½œ
    if not test_basic_operations(index):
        return

    # 4. ä¸Šä¼ æ¼”ç¤ºçŸ¥è¯†
    if not upload_demo_knowledge(index):
        print("âš ï¸ Demo knowledge upload failed, but basic operations work")

    print("\nğŸ‰ All tests completed successfully!")
    print(f"âœ… Your Pinecone index '{INDEX_NAME}' is ready to use!")
    print("\nNext steps:")
    print("1. Install dependencies: pip install sentence-transformers fastapi line-bot-sdk")
    print("2. Set up your LINE Bot credentials")
    print("3. Run the main application: python main.py")

if __name__ == "__main__":
    main()

---

# requirements_minimal.txt - æœ€å°ä¾èµ–ç‰ˆæœ¬
pinecone-client==3.0.0
sentence-transformers==2.2.2
fastapi==0.104.1
uvicorn==0.24.0
line-bot-sdk==3.8.0
pydantic==2.5.0
python-multipart==0.0.6

---

# replit_secrets_setup.md
# åœ¨ Replit ä¸­è®¾ç½®è¿™äº› Secrets:

PINECONE_API_KEY=pcsk_4WvWXx_G5bRUFdFNzLzRHNM9rkvFMvC18TMRTaeYXVCxmWSPQLmKr4xAs4UaZg5NvVb69m
PINECONE_INDEX_NAME=dementia-care-knowledge
LINE_CHANNEL_ACCESS_TOKEN=your_line_token_here
LINE_CHANNEL_SECRET=your_line_secret_here

# å¿«é€Ÿéƒ¨ç½²å‘½ä»¤:
# 1. è¿è¡Œæµ‹è¯•: python quick_test.py
# 2. å¦‚æœæµ‹è¯•é€šè¿‡ï¼Œå®‰è£…å®Œæ•´ä¾èµ–: pip install -r requirements_minimal.txt  
# 3. è¿è¡Œä¸»åº”ç”¨: python main.py

---

# simple_main.py - ç®€åŒ–ç‰ˆä¸»åº”ç”¨ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
from fastapi import FastAPI
from pinecone import Pinecone
import json

app = FastAPI()

# åˆå§‹åŒ– Pinecone
pc = Pinecone(api_key="pcsk_4WvWXx_G5bRUFdFNzLzRHNM9rkvFMvC18TMRTaeYXVCxmWSPQLmKr4xAs4UaZg5NvVb69m")
index = pc.Index("dementia-care-knowledge")

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ - æ˜¾ç¤ºçŠ¶æ€"""
    try:
        stats = index.describe_index_stats()
        return {
            "message": "ğŸ‰ XAI Dementia Care Bot is running!",
            "status": "healthy",
            "pinecone_vectors": stats.total_vector_count,
            "index_name": "dementia-care-knowledge"
        }
    except Exception as e:
        return {
            "message": "âš ï¸ Service running but Pinecone connection issues",
            "error": str(e)
        }

@app.get("/test-query")
async def test_query(q: str = "å¤±æ™ºç—‡ç—‡çŠ¶"):
    """æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½"""
    try:
        # ç®€å•çš„æ–‡æœ¬æŸ¥è¯¢ï¼ˆä¸ä½¿ç”¨åµŒå…¥æ¨¡å‹ï¼‰
        # åœ¨å®é™…åº”ç”¨ä¸­ä¼šä½¿ç”¨ sentence-transformers

        # æ¨¡æ‹ŸæŸ¥è¯¢ç»“æœ
        return {
            "query": q,
            "message": "âœ… Query endpoint working",
            "note": "Install sentence-transformers for full functionality"
        }
    except Exception as e:
        return {"error": str(e)}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

---

# å®Œæ•´éƒ¨ç½²æ£€æŸ¥æ¸…å•:

# âœ… ç¬¬ä¸€æ­¥: æµ‹è¯• Pinecone è¿æ¥
# python quick_test.py

# âœ… ç¬¬äºŒæ­¥: å®‰è£…å¿…è¦ä¾èµ–  
# pip install sentence-transformers fastapi uvicorn line-bot-sdk

# âœ… ç¬¬ä¸‰æ­¥: æµ‹è¯•ç®€åŒ–åº”ç”¨
# python simple_main.py

# âœ… ç¬¬å››æ­¥: è®¾ç½® LINE Bot credentials
# åœ¨ Replit Secrets ä¸­æ·»åŠ  LINE_CHANNEL_ACCESS_TOKEN å’Œ LINE_CHANNEL_SECRET

# âœ… ç¬¬äº”æ­¥: è¿è¡Œå®Œæ•´åº”ç”¨
# python main.py (ä½¿ç”¨ä¹‹å‰æä¾›çš„å®Œæ•´ä»£ç )